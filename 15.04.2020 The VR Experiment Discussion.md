## Experiment Flow

1. Setup of the VR system and sensor recording system
2. Participant comes in and is given an introduction letter together with some documents to agree that his/her data is been recorded
3. Attaching sensors to  the participant
4. Relaxation phase: 3-5 minutes, playing relaxation music, put on HMD with relaxing 360 video
5. All the time: Participant talks what he sees, what he does. (like in a real firefighter mission)
6. Starting experiment with label "lowstress"
   * Task: The participant navigates through the environment with the goal to find and rescue a victim, who is in danger.
   * Stressors: Unknown environment. No time limit and no additional stressors.
   * End: After the participant found the victim, this experiment part ends.
7. Starting experiment with label "mediumstress"
   * Task: same, different corridors/rooms
   * Stressors:
     * Unknown environment
     * Stressful audio cues (screaming, fire sounds)
     * Distorted bad communication audio (audio gets overlayed by environment noise). Triggerboxes play audio. Waits for a specific time. (Record audio for stress detection)
     * Fire and smoke
   * End: same
8. (The participant is asked if he/she feels fine and can continue or wants to make a small break from VR)

8. Starting experiment with label "highstress"
   * Task: same, different corridors/rooms
   * Stressors: 
     * Stressful audio cues (screaming, fire sounds)
     * Fire and smoke
     * Time limitation through a display of your remaining oxygen level
     * Additional props are appearing in the scene to further differentiate the environment from previous ones
     * Participant cant walk normally and needs to crouch, because he cant see something in the smoke
   * End: same

9. Participant finishes the VR experiment and now needs to fill out questionnaires.
   * Questionnaire about how he felt during each part of the experiment (checking the labeling quality)
   * Questionnaire about demography, personality and stress management (building a user profile)
   * ...



#### Triggerboxes

* High grained stress labels:
  * Asked participant about his stress (audio)
  * Visual display: How do you feel. Smiles. Asked maybe every minute. Where to position it?
  * Physical 3D pannel with buttons to ask for stress.
  * Stress question display on wrist
  * Dead man button: Stress emergency button

* Context labels about where is the participant on the current timestamp





## VR Stressor System (Unity3D)



### Dimension Stacking

8*8 meter tracking area

VR environment is mapped 1:1 to the tracking area, thus the participant is able to traverse through the environment through normal physical walking.

Different dimensions of the VR environment, stacked on top of each other, with seamless unnoticeable transitions when you move from one dimension to the other.

**Done:** First prototype of this method has been implemented

**Todo:** 

* Needs to test the dimension stacking prototype in VR with an 8*8m tracking area. 
* Implementation of the method can be improved by laying out each dimension next to each other and not on top of each other, which would enable e.g. building of lightmaps to enhance the graphics quality.
* Improve the models/materials/lighting to further enhance the graphics quality



### Main Scripts

**ExperimentSettings** Global point for all settings about the experiment. 

**ObjectManager** Applies configurations from the ExprimentSettings to the objects inside the scene.

**ExperimentState** The current state of the experiment.  e.g.: Experiment running or gameover. Player oxygen and life. Remaining time etc.

**UIManager** Updates UI to display all relevant experiment state information to the user.

**NetworkManager** Sends out all relevant data to external applications.



A lot of scripts for dimension stacking to render correctly on texture and traverse user through portals.

Scripts for player control. 



**Done:** Implementation of all main scripts, but needs testing for bugs.

**Todo:** 

* Player interaction (put a mask on the victim)
  * Goals:
    * save victim
    * shut down electricity
    * close gas source
    * extinguish fire
* Network
* Eyetracker



### Network communication (Unity <--> DataRecorder)

#### Unity

At the start and end of an experiment part with label XY, Unity sends a message to a socket with the current label and the configurations of the current experiment part.

In a separate thread, unity reads all the time the realtime eyetracking data and writes it onto a socket.

 

#### DataRecorder (Python)

Listens to the socket. Receives the label and config data and starts/stops the recording process depending on incoming unity events.

In addition to the datastream from the Biosignalplux system, the eyetracking data is read from the socket.



